{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b485054-8e5d-49fb-935c-2ce5e6b66b57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /databricks/python3/lib/python3.11/site-packages (2.3.1+cpu)\nRequirement already satisfied: torchvision in /databricks/python3/lib/python3.11/site-packages (0.18.1+cpu)\nCollecting torchaudio\n  Obtaining dependency information for torchaudio from https://files.pythonhosted.org/packages/41/33/0f21b15f8e231bb55578f6b32e8c18675585b7bf97cb0aee96b1591e4193/torchaudio-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata\n  Downloading torchaudio-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\nRequirement already satisfied: transformers in /databricks/python3/lib/python3.11/site-packages (4.41.2)\nCollecting faiss-cpu\n  Obtaining dependency information for faiss-cpu from https://files.pythonhosted.org/packages/51/b2/4f9abd2b859cef0e2332d3ff032e1973281fac1204fa8da14effc326f528/faiss_cpu-1.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading faiss_cpu-1.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.11/site-packages (from torch) (3.13.4)\nRequirement already satisfied: typing-extensions>=4.8.0 in /databricks/python3/lib/python3.11/site-packages (from torch) (4.10.0)\nRequirement already satisfied: sympy in /databricks/python3/lib/python3.11/site-packages (from torch) (1.11.1)\nRequirement already satisfied: networkx in /databricks/python3/lib/python3.11/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.11/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /databricks/python3/lib/python3.11/site-packages (from torch) (2023.5.0)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.11/site-packages (from torchvision) (1.23.5)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /databricks/python3/lib/python3.11/site-packages (from torchvision) (9.4.0)\nINFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\nCollecting torchaudio\n  Obtaining dependency information for torchaudio from https://files.pythonhosted.org/packages/17/ed/d6e73554726a4aea054353093f3dffe68ea18f006d14c0604e651f3e6ee0/torchaudio-2.5.0-cp311-cp311-manylinux1_x86_64.whl.metadata\n  Downloading torchaudio-2.5.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n  Obtaining dependency information for torchaudio from https://files.pythonhosted.org/packages/cc/f3/a950329a25ee1af14c05065ce6c1751f031de9e6d5eebb0620ce3d0938ed/torchaudio-2.4.1-cp311-cp311-manylinux1_x86_64.whl.metadata\n  Downloading torchaudio-2.4.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n  Obtaining dependency information for torchaudio from https://files.pythonhosted.org/packages/b7/a7/6b1c6185c9aed923f64fd6c3d1cce09b21031ab36aa661f39e255535511c/torchaudio-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata\n  Downloading torchaudio-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n  Obtaining dependency information for torchaudio from https://files.pythonhosted.org/packages/62/04/3acb3673dcc9f493e65798d752841137cfcc14220a8eb4ec8dc202382bcc/torchaudio-2.3.1-cp311-cp311-manylinux1_x86_64.whl.metadata\n  Downloading torchaudio-2.3.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /databricks/python3/lib/python3.11/site-packages (from transformers) (0.23.4)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.11/site-packages (from transformers) (23.2)\nRequirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.11/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /databricks/python3/lib/python3.11/site-packages (from transformers) (2022.7.9)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.11/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /databricks/python3/lib/python3.11/site-packages (from transformers) (0.19.0)\nRequirement already satisfied: safetensors>=0.4.1 in /databricks/python3/lib/python3.11/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /databricks/python3/lib/python3.11/site-packages (from transformers) (4.65.0)\nCollecting numpy (from torchvision)\n  Obtaining dependency information for numpy from https://files.pythonhosted.org/packages/7a/f0/80811e836484262b236c684a75dfc4ba0424bc670e765afaa911468d9f39/numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/62.0 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.0/62.0 kB\u001B[0m \u001B[31m4.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /databricks/python3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\nDownloading torchaudio-2.3.1-cp311-cp311-manylinux1_x86_64.whl (3.4 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.4 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.6/3.4 MB\u001B[0m \u001B[31m17.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m3.3/3.4 MB\u001B[0m \u001B[31m61.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.4/3.4 MB\u001B[0m \u001B[31m47.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading faiss_cpu-1.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/27.5 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.7/27.5 MB\u001B[0m \u001B[31m202.2 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.9/27.5 MB\u001B[0m \u001B[31m188.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━\u001B[0m \u001B[32m20.0/27.5 MB\u001B[0m \u001B[31m196.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━\u001B[0m \u001B[32m26.1/27.5 MB\u001B[0m \u001B[31m192.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m27.5/27.5 MB\u001B[0m \u001B[31m192.1 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m27.5/27.5 MB\u001B[0m \u001B[31m192.1 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m27.5/27.5 MB\u001B[0m \u001B[31m192.1 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m27.5/27.5 MB\u001B[0m \u001B[31m57.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/16.3 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.4/16.3 MB\u001B[0m \u001B[31m177.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━\u001B[0m \u001B[32m11.9/16.3 MB\u001B[0m \u001B[31m174.1 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m16.3/16.3 MB\u001B[0m \u001B[31m194.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m16.3/16.3 MB\u001B[0m \u001B[31m194.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m16.3/16.3 MB\u001B[0m \u001B[31m84.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hInstalling collected packages: numpy, faiss-cpu, torchaudio\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.23.5\n    Not uninstalling numpy at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-4692d204-ff8a-43ae-a18b-fc5ab34d05a8\n    Can't uninstall 'numpy'. No files were found to uninstall.\n\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npetastorm 0.12.1 requires pyspark>=2.1.0, which is not installed.\ndatabricks-feature-engineering 0.6.0 requires numpy<2,>=1.19.2, but you have numpy 2.1.3 which is incompatible.\nlangchain 0.1.20 requires numpy<2,>=1, but you have numpy 2.1.3 which is incompatible.\nlangchain-community 0.0.38 requires numpy<2,>=1, but you have numpy 2.1.3 which is incompatible.\nnumba 0.57.1 requires numpy<1.25,>=1.21, but you have numpy 2.1.3 which is incompatible.\nscipy 1.11.1 requires numpy<1.28.0,>=1.21.6, but you have numpy 2.1.3 which is incompatible.\ntensorflow 2.16.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.1.3 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 2.1.3 which is incompatible.\u001B[0m\u001B[31m\n\u001B[0mSuccessfully installed faiss-cpu-1.9.0 numpy-2.1.3 torchaudio-2.3.1\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio transformers faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "534cc83a-0700-4fd5-a70d-36d1b0fd65e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /local_disk0/.ephemeral_nfs/envs/pythonEnv-4692d204-ff8a-43ae-a18b-fc5ab34d05a8/lib/python3.11/site-packages (2.1.3)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dffcbeb-c528-4e56-9a1f-7aac5e2bc888",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5505dfb804ef4fe7bf49b2cd135a567a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b43d278ca044e7e87cb725092fb4fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c550d6be2941cfa68ef7e7fdb8a23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c92b0d838eb421aad1b1a0532a8c4a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f8fb4414df4010a7343a85dbc9de5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884f61f01e9c4bbca3e2a63f31a39f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "# Step 1: Embed Documents (same as before)\n",
    "def embed_documents(documents):\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for doc in documents:\n",
    "            inputs = tokenizer(doc, return_tensors='pt', padding=True, truncation=True)\n",
    "            outputs = model(**inputs)\n",
    "            embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "            embeddings.append(embedding)\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "# Step 2: Create FAISS Vector Index (same as before)\n",
    "def create_vector_index(embeddings):\n",
    "    dim = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(embeddings)\n",
    "    return index\n",
    "\n",
    "# Step 3: Search Similar Documents (same as before)\n",
    "def search_similar_documents(index, query_embedding, top_k=5):\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "    return distances, indices\n",
    "\n",
    "# Step 4: Retrieve Relevant Context (same as before)\n",
    "def retrieve_context(query, index, documents):\n",
    "    query_embedding = embed_documents([query])\n",
    "    distances, indices = search_similar_documents(index, query_embedding)\n",
    "    return [documents[i] for i in indices[0]]\n",
    "\n",
    "# Step 5: Generate Response Using Retrieved Context\n",
    "def generate_response(query, context_docs):\n",
    "    model_name = \"gpt2\"  # or any other causal language model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    \n",
    "    # Combine the query and retrieved documents as context for generation\n",
    "    context_text = \" \".join(context_docs)\n",
    "    prompt = f\"Query: {query}\\nContext: {context_text}\\nAnswer:\"\n",
    "    \n",
    "    # Tokenize input and generate response\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs.input_ids, max_length=150, num_return_sequences=1)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Example Documents\n",
    "documents = [\n",
    "    \"AI is transforming healthcare.\",\n",
    "    \"Machine learning is a subset of artificial intelligence.\",\n",
    "    \"Deep learning enables many modern AI applications.\",\n",
    "    \"Natural Language Processing is a field of AI.\",\n",
    "    \"AI technologies are becoming more pervasive in various industries.\"\n",
    "]\n",
    "\n",
    "# Embedding and Indexing\n",
    "document_embeddings = embed_documents(documents)\n",
    "index = create_vector_index(document_embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d4a6791-97b4-4b20-b808-b7c636cad035",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a2c4d33eb14ad7b7c113accb11dbea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d48c4f653964c31846dc240194b9266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506b969769084ebfa29ca4b7ee6e72b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634359dc84ce46659e67818eeda4f5ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c09ef70b8054751aa5ec4499eb4bd8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "048ed7f6e8c54942af5b5641c9b1865c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088b78acf63c44f3b51234676163dc2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Context for Query:\nDocument: 'AI is transforming healthcare.'\nDocument: 'AI technologies are becoming more pervasive in various industries.'\nDocument: 'Machine learning is a subset of artificial intelligence.'\nDocument: 'Natural Language Processing is a field of AI.'\nDocument: 'Deep learning enables many modern AI applications.'\n\nGenerated Response:\nQuery: How is AI used in healthcare?\nContext: AI is transforming healthcare. AI technologies are becoming more pervasive in various industries. Machine learning is a subset of artificial intelligence. Natural Language Processing is a field of AI. Deep learning enables many modern AI applications.\nAnswer: AI is transforming healthcare. AI technologies are becoming more pervasive in various industries. Machine learning is a subset of artificial intelligence. Natural Language Processing is a field of AI. Deep learning enables many modern AI applications.\nQuestion: How is AI used in healthcare?\nContext: AI is transforming healthcare. AI technologies are becoming more widespread in various industries. Machine learning is a subset of artificial intelligence. Natural Language Processing is a field of AI. Deep learning enables many modern AI applications\n"
     ]
    }
   ],
   "source": [
    " # Query and Retrieve Context\n",
    "query = \"How is AI used in healthcare?\"\n",
    "retrieved_context = retrieve_context(query, index, documents)\n",
    "\n",
    "# Generate Response\n",
    "generated_response = generate_response(query, retrieved_context)\n",
    "\n",
    "# Output Retrieved Context and Generated Response\n",
    "print(\"Retrieved Context for Query:\")\n",
    "for doc in retrieved_context:\n",
    "    print(f\"Document: '{doc}'\")\n",
    "\n",
    "print(\"\\nGenerated Response:\")\n",
    "print(generated_response)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "RAG 2024-11-09 17:44:57",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
